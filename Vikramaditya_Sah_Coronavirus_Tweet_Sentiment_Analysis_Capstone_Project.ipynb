{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikram0050/Coronavirus-Tweet-Sentiment-Analysis/blob/main/Vikramaditya_Sah_Coronavirus_Tweet_Sentiment_Analysis_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Sentiment Analysis : Predicting sentiment of COVID-19 tweets</u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### This challenge asks you to build a classification model to predict the sentiment of COVID-19 tweets.The tweets have been pulled from Twitter and manual tagging has been done then.\n",
        "\n",
        "### The names and usernames have been given codes to avoid any privacy concerns.\n",
        "\n",
        "### You are given the following information:\n",
        "1. Location\n",
        "2. Tweet At\n",
        "3. Original Tweet\n",
        "4. Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqzNoCsr8AiZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV9OBTg78Cs9"
      },
      "outputs": [],
      "source": [
        "#read csv file\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/corona/Coronavirus Tweets.csv\" , encoding='latin-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_nbavAGI_QS"
      },
      "source": [
        "# DATA OVERVIEW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8yDEDcn9DGa"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SCPNbWvE5Cj"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lM8NI0dE7I5"
      },
      "outputs": [],
      "source": [
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcRj0UjtE_Jt"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8-bwjhYFB_T"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7bm51hdFJPB"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGff7R9bFLo4"
      },
      "outputs": [],
      "source": [
        "df.Sentiment.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKOTRe8ZJOU3"
      },
      "source": [
        "**DATA INFORMATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRRKgsI6JS1n"
      },
      "source": [
        "We have 41157 rows and 6 columns in our dataset with null values present only in location, which will not affect our model as we will not be using this feature. Here our target variable will be Sentiment, which has 5 unique values- 'Neutral', 'Positive', 'Extremely Negative', 'Negative' and 'Extremely Positive'. Out of the other 5 features, the only column we really need for our classification project is OriginalTweet ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeMqAZdTFNn_"
      },
      "outputs": [],
      "source": [
        "#copying data to preserve orignal file\n",
        "df1= df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cok9CR8uJaAC"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD2LPdpwFQew"
      },
      "outputs": [],
      "source": [
        "#check duplicate entries\n",
        "len(df1[df1.duplicated()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFW9mwE3FTNc"
      },
      "outputs": [],
      "source": [
        "#sentiment count\n",
        "df1.Sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDrEYJeGFVlL"
      },
      "outputs": [],
      "source": [
        "#plotting sentiment count\n",
        "sns.catplot(\"Sentiment\", data=df1, kind=\"count\",height=7,aspect=1.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz4pxtv-FYfi"
      },
      "outputs": [],
      "source": [
        "#sentiment count\n",
        "count=df1.Location.value_counts().head(10)\n",
        "df1.Location.value_counts().head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VQbAplbFcT5"
      },
      "outputs": [],
      "source": [
        "#plotting sentiment count\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "ax = fig.gca()\n",
        "count.plot(ax = ax, kind='bar')\n",
        "ax.set_title('Location wise Tweet Count')\n",
        "ax.set_xlabel('Location') \n",
        "ax.set_ylabel('Tweet Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzf5xwciKOL9"
      },
      "source": [
        "Maximum tweets are done from London and US."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U7w0iaPKVEO"
      },
      "source": [
        "# TEXT PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcYFJGgJKcgp"
      },
      "source": [
        "**REMOVING LINKS/URLs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9Br4djpIW95"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "df1['OriginalTweet'] = df1['OriginalTweet'].apply(lambda x: re.sub('https?://[A-Za-z0-9./]+',' ', str(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAr4MGwOKn5Q"
      },
      "outputs": [],
      "source": [
        "#orignal data\n",
        "df.OriginalTweet[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEZau9A1KuEq"
      },
      "outputs": [],
      "source": [
        "#copied data\n",
        "df1.OriginalTweet[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urkq5N9NKyeQ"
      },
      "outputs": [],
      "source": [
        "df1['OriginalTweet'] = df1['OriginalTweet'].apply(lambda x: re.sub('@[\\w]*',' ', str(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW54UDK_K3HA"
      },
      "outputs": [],
      "source": [
        "#result\n",
        "df1.OriginalTweet[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsN1Zof4K53_"
      },
      "outputs": [],
      "source": [
        "df1['OriginalTweet'] = df1['OriginalTweet'].apply(lambda x: re.sub('[^a-zA-Z]',' ', str(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOd96Zc3K9h9"
      },
      "outputs": [],
      "source": [
        "#result\n",
        "df1.OriginalTweet[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuyGuLaiLAgr"
      },
      "outputs": [],
      "source": [
        "#Importing Stop-words\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSI5OSS5LD4M"
      },
      "outputs": [],
      "source": [
        "#function to remove stopwords and tokenize\n",
        "def remove_stopwords(text):\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "    return (text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwY3bprqLHLP"
      },
      "outputs": [],
      "source": [
        "df1['OriginalTweet']= df1['OriginalTweet'].apply(lambda x: remove_stopwords(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAikKWbMLKUA"
      },
      "outputs": [],
      "source": [
        "#result\n",
        "df1.OriginalTweet[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR0IfjFCL0ec"
      },
      "source": [
        "**REMOVING SHORT WORDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jccHflBeLbjy"
      },
      "outputs": [],
      "source": [
        "#Removing words with than 3 letters\n",
        "df1['OriginalTweet'] = df1['OriginalTweet'].apply(lambda x: (w for w in x if len(w)>3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3c7aZnTL9st"
      },
      "source": [
        "**STEMMING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSVBvctOL661"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mgIHr14ME5Y"
      },
      "outputs": [],
      "source": [
        "#function for stemming\n",
        "def stemming(text):    \n",
        "    text = [stemmer.stem(word) for word in text]\n",
        "    return (\" \".join(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLg2eTOvMJCO"
      },
      "outputs": [],
      "source": [
        "df1['OriginalTweet'] = df1['OriginalTweet'].apply(lambda x: stemming(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3Z-cmLbMNIb"
      },
      "outputs": [],
      "source": [
        "#result\n",
        "df1.OriginalTweet[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3LoLECmMW20"
      },
      "source": [
        "**DATA ENCODING**\n",
        "\n",
        "We will now encode our target variable - Sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N6R-rkZMUr7"
      },
      "outputs": [],
      "source": [
        "#function to encode \n",
        "\n",
        "def encode(sentiment):\n",
        "    if sentiment=='Neutral':  \n",
        "        return 0                                                         # Changing neutral labels as 0\n",
        "    elif (sentiment=='Positive') or  (sentiment=='Extremely Positive'):  \n",
        "        return 1                                                         # Combining Positive and extremely positive labels as 1\n",
        "    else:\n",
        "        return -1                                                        # Combining Negative and extremely negative labels as -1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2s0DYY4Mgm-"
      },
      "outputs": [],
      "source": [
        "df1['Sentiment'] = df1['Sentiment'].apply(encode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyW5OIdsMkh1"
      },
      "outputs": [],
      "source": [
        "#taking a look at modified data\n",
        "df1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbqapK7OMnoM"
      },
      "outputs": [],
      "source": [
        "# Plotting the counts of encoded Sentiment\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot('Sentiment', data=df1)\n",
        "plt.title(\"Counts of Sentiments after encoding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZWQcfVbMtwb"
      },
      "source": [
        "# WORD CLOUD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kjJJedwMqr3"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "stopwords = set(STOPWORDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfxTI6ujM3_i"
      },
      "outputs": [],
      "source": [
        "#word cloud for neutral sentiment\n",
        "words=' '.join(text for text in df1['OriginalTweet'][df1['Sentiment'] == 0])\n",
        " \n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='black',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(words)\n",
        " \n",
        "# plot the WordCloud image                      \n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQwFNNQKM7cJ"
      },
      "outputs": [],
      "source": [
        "#word cloud for positive sentiment\n",
        "words=' '.join(text for text in df1['OriginalTweet'][df1['Sentiment'] == 1])\n",
        " \n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='black',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(words)\n",
        " \n",
        "# plot the WordCloud image                      \n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kidzfJkNAOi"
      },
      "outputs": [],
      "source": [
        "#word cloud for negative sentiment\n",
        "words=' '.join(text for text in df1['OriginalTweet'][df1['Sentiment'] == -1])\n",
        " \n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='black',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(words)\n",
        " \n",
        "# plot the WordCloud image                      \n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        " \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H66V3-i5NqCs"
      },
      "source": [
        "#**VECTORIZATION AND DATA SPLIT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QahJcXcNEq4"
      },
      "outputs": [],
      "source": [
        "#getting usable features\n",
        "df2=df1[['OriginalTweet','Sentiment']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne8ee7QTN4lp"
      },
      "outputs": [],
      "source": [
        "#train test split\n",
        "from sklearn.model_selection import train_test_split \n",
        "train,test = train_test_split(df2,test_size = 0.2,random_state=0,stratify = df2.Sentiment.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cugt6t6KOLue"
      },
      "outputs": [],
      "source": [
        "#vectorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = list(stopwords.words('english'))\n",
        "vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n",
        "\n",
        "x_train = vectorizer.fit_transform(train.OriginalTweet.values)\n",
        "x_test = vectorizer.transform(test.OriginalTweet.values)\n",
        "\n",
        "y_train = train.Sentiment.values\n",
        "y_test = test.Sentiment.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jN3ZrKIOQdL"
      },
      "outputs": [],
      "source": [
        "#shape of split data\n",
        "print(\"X_train.shape : \", x_train.shape)\n",
        "print(\"X_test.shape : \", x_test.shape)\n",
        "print(\"y_train.shape : \", y_train.shape)\n",
        "print(\"y_test.shape : \", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Avha3tkOZBb"
      },
      "source": [
        "**DATAFRAME TO STORE EVALUATION METRICS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYLCoVdUOch9"
      },
      "source": [
        "I will store the evaluation metrics for each model into this data frame to compare at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78MVFbT0OVHh"
      },
      "outputs": [],
      "source": [
        "#empty data frame creation\n",
        "i=0\n",
        "error_df=pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnkZKU_cOtFQ"
      },
      "source": [
        "# LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyldM-JJOxD9"
      },
      "source": [
        "From this point we'll fit the data in various models and get our output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UjlJj9-Oi5I"
      },
      "outputs": [],
      "source": [
        "#hyperparameter tuning\n",
        "logr = LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06J8sIMH1Tuu"
      },
      "outputs": [],
      "source": [
        "#fitting data\n",
        "logr.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PYlQ72nROkh"
      },
      "outputs": [],
      "source": [
        "#prediction\n",
        "y_pred = logr.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDXhWXVzRiYY"
      },
      "outputs": [],
      "source": [
        "#evaluation metrics\n",
        "\n",
        "#F1 score\n",
        "f1score = f1_score(y_test,y_pred,average='weighted')\n",
        "\n",
        "#Accuracy\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "\n",
        "#precision\n",
        "prec = precision_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "#recall\n",
        "recall=recall_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "print('Accuracy :' ,acc)\n",
        "print('Precision :', prec)\n",
        "print('Recall :', recall)\n",
        "print('F1 score :' ,f1score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rwYNZNARx6d"
      },
      "outputs": [],
      "source": [
        "#Inserting errors in dataframe\n",
        "\n",
        "error_df.loc[i,\"Model_Name\"]='LOGISTIC REGRESSION'\n",
        "error_df.loc[i,\"Accuracy\"]=round(acc,4)\n",
        "error_df.loc[i,\"Precision\"]=round(prec,4)\n",
        "error_df.loc[i,\"Recall\"]=round(recall,4)\n",
        "error_df.loc[i,\"F1 score\"]=round(f1score,4)\n",
        "\n",
        "\n",
        "i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JHJyEAv2EFY"
      },
      "source": [
        "# XGBoost CLASSIFIER\n",
        "\n",
        "Note- not doing hyperparameter tuning because i tried giving manual input but it's giving better results without any intervention."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting data\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "FKQ6B4n7wFuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "y_pred = xgb.predict(x_test)"
      ],
      "metadata": {
        "id": "jXaiRKJwwIJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation metrics\n",
        "\n",
        "#F1 score\n",
        "f1score = f1_score(y_test,y_pred,average='weighted')\n",
        "\n",
        "#Accuracy\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "\n",
        "#precision\n",
        "prec = precision_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "#recall\n",
        "recall=recall_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "print('Accuracy :' ,acc)\n",
        "print('Precision :', prec)\n",
        "print('Recall :', recall)\n",
        "print('F1 score :' ,f1score)"
      ],
      "metadata": {
        "id": "qalUOxrcxxjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inserting errors in dataframe\n",
        "\n",
        "error_df.loc[i,\"Model_Name\"]='XGBOOST CLASSIFIER'\n",
        "error_df.loc[i,\"Accuracy\"]=round(acc,4)\n",
        "error_df.loc[i,\"Precision\"]=round(prec,4)\n",
        "error_df.loc[i,\"Recall\"]=round(recall,4)\n",
        "error_df.loc[i,\"F1 score\"]=round(f1score,4)\n",
        "\n",
        "\n",
        "i+=1\n"
      ],
      "metadata": {
        "id": "T6XEfxnGx0Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN CLASSIFIER\n"
      ],
      "metadata": {
        "id": "YwVDigaayL00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter tuning\n",
        "reg = KNeighborsClassifier()\n",
        "param = {'n_neighbors': [1,2,3,4,5,6,7,8]}"
      ],
      "metadata": {
        "id": "u1kX_Y-b0emA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting data\n",
        "knn = GridSearchCV(estimator=reg,param_grid=param)\n",
        "knn.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "q684XKB-0n-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "y_pred = knn.predict(x_test)"
      ],
      "metadata": {
        "id": "TxOMIJRh0rND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation metrics\n",
        "\n",
        "#F1 score\n",
        "f1score = f1_score(y_test,y_pred,average='weighted')\n",
        "\n",
        "#Accuracy\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "\n",
        "#precision\n",
        "prec = precision_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "#recall\n",
        "recall=recall_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "print('Accuracy :' ,acc)\n",
        "print('Precision :', prec)\n",
        "print('Recall :', recall)\n",
        "print('F1 score :' ,f1score)\n"
      ],
      "metadata": {
        "id": "9MjcOLlq1nTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inserting errors in dataframe\n",
        "\n",
        "error_df.loc[i,\"Model_Name\"]='KNN CLASSIFIER'\n",
        "error_df.loc[i,\"Accuracy\"]=round(acc,4)\n",
        "error_df.loc[i,\"Precision\"]=round(prec,4)\n",
        "error_df.loc[i,\"Recall\"]=round(recall,4)\n",
        "error_df.loc[i,\"F1 score\"]=round(f1score,4)\n",
        "\n",
        "\n",
        "i+=1"
      ],
      "metadata": {
        "id": "qevDEqjE1qwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM CLASSIFIER"
      ],
      "metadata": {
        "id": "saH_eQAe1uta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter tuning\n",
        "reg = SVC()\n",
        "param = {     'C': [0.1, 1, 10, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001],\n",
        "              'kernel': ['rbf']\n",
        "        }\n",
        "svm = GridSearchCV(reg,param)"
      ],
      "metadata": {
        "id": "a8zANEaO3bZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting data\n",
        "svm = SVC()\n",
        "svm.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "_6yt6JNS2yjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "y_pred = svm.predict(x_test)"
      ],
      "metadata": {
        "id": "fb0MrUsV2A3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation metrics\n",
        "\n",
        "#F1 score\n",
        "f1score = f1_score(y_test,y_pred,average='weighted')\n",
        "\n",
        "#Accuracy\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "\n",
        "#precision\n",
        "prec = precision_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "#recall\n",
        "recall=recall_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "print('Accuracy :' ,acc)\n",
        "print('Precision :', prec)\n",
        "print('Recall :', recall)\n",
        "print('F1 score :' ,f1score)"
      ],
      "metadata": {
        "id": "02R7OwKn2VyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inserting errors in dataframe\n",
        "\n",
        "error_df.loc[i,\"Model_Name\"]='SVM CLASSIFIER'\n",
        "error_df.loc[i,\"Accuracy\"]=round(acc,4)\n",
        "error_df.loc[i,\"Precision\"]=round(prec,4)\n",
        "error_df.loc[i,\"Recall\"]=round(recall,4)\n",
        "error_df.loc[i,\"F1 score\"]=round(f1score,4)\n",
        "\n",
        "\n",
        "i+=1"
      ],
      "metadata": {
        "id": "Ca4QomwV7k7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM FOREST CLASSIFIER"
      ],
      "metadata": {
        "id": "OI_D4IgW7tqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter tuning\n",
        "classifier = RandomForestClassifier()\n",
        "parameters = {'n_estimators':[100, 200, 300], 'max_depth':[80, 90, 100, 110]}\n",
        "rf = RandomizedSearchCV(classifier, param_distributions= parameters, cv=5,n_jobs=-1)"
      ],
      "metadata": {
        "id": "-1bLB3KtRAZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting data\n",
        "rf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "o3xKeMBhXaYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "y_pred = rf.predict(x_test)"
      ],
      "metadata": {
        "id": "mvxaUVdA78U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation metrics\n",
        "\n",
        "#F1 score\n",
        "f1score = f1_score(y_test,y_pred,average='weighted')\n",
        "\n",
        "#Accuracy\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "\n",
        "#precision\n",
        "prec = precision_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "#recall\n",
        "recall=recall_score(y_test,y_pred, average='weighted')\n",
        "\n",
        "print('Accuracy :' ,acc)\n",
        "print('Precision :', prec)\n",
        "print('Recall :', recall)\n",
        "print('F1 score :' ,f1score)"
      ],
      "metadata": {
        "id": "TrSUIvp18Drc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inserting errors in dataframe\n",
        "\n",
        "error_df.loc[i,\"Model_Name\"]='RANDOM FOREST CLASSIFIER'\n",
        "error_df.loc[i,\"Accuracy\"]=round(acc,4)\n",
        "error_df.loc[i,\"Precision\"]=round(prec,4)\n",
        "error_df.loc[i,\"Recall\"]=round(recall,4)\n",
        "error_df.loc[i,\"F1 score\"]=round(f1score,4)\n",
        "\n",
        "\n",
        "i+=1"
      ],
      "metadata": {
        "id": "YlMOnZjo8IRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL COMPARISION\n",
        "\n",
        "We will now compare performance of all the classification models-"
      ],
      "metadata": {
        "id": "VytJcmGxjPdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sorting by F1 score\n",
        "error_df.sort_values(by=['F1 score'],ascending=False,inplace=True)\n",
        "error_df=error_df.reset_index()\n",
        "error_df.drop(labels='index',axis=1)"
      ],
      "metadata": {
        "id": "Zs62Dpu4nN9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONCLUSION\n",
        "We can conclude that Logistic regression is the best model for our dataset, followed closely by SVM classifier and Random Forest classifier. XGboost and KNN classifiers did not give a good result compared to others."
      ],
      "metadata": {
        "id": "bZtamJrajeG_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "V_nbavAGI_QS",
        "cok9CR8uJaAC",
        "_U7w0iaPKVEO",
        "KZWQcfVbMtwb",
        "H66V3-i5NqCs",
        "xnkZKU_cOtFQ",
        "0JHJyEAv2EFY",
        "YwVDigaayL00",
        "saH_eQAe1uta"
      ],
      "name": " Vikramaditya Sah - Coronavirus Tweet Sentiment Analysis - Capstone Project.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}